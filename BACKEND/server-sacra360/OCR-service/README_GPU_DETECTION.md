# Sacra360 OCR Service - Soporte Multi-GPU

## üéØ Resumen

El servicio OCR ahora detecta autom√°ticamente el tipo de GPU disponible y se adapta:

- ‚úÖ **GPU NVIDIA con CUDA**: Usa aceleraci√≥n GPU completa (10-15x m√°s r√°pido)
- ‚úÖ **GPU AMD/Intel/Otros**: Fallback a CPU optimizado con quantizaci√≥n
- ‚úÖ **Sin GPU**: CPU optimizado

## üîç Detecci√≥n Autom√°tica

El sistema verifica en orden:

1. **Hardware GPU f√≠sico** (v√≠a OpenCL): AMD, NVIDIA, Intel, etc.
2. **CUDA disponible** (v√≠a PyTorch): Solo NVIDIA
3. **Decisi√≥n**: GPU si CUDA disponible, sino CPU optimizado

## üöÄ Modos de Operaci√≥n

### Modo GPU NVIDIA/CUDA (M√°s R√°pido)
```
Hardware: NVIDIA GTX/RTX/T4/A100
Software: CUDA + PyTorch GPU
Velocidad: ~1 minuto (Tabla1.pdf, 136 celdas)
Optimizaciones: GPU nativa, sin cuantizaci√≥n
```

**Cu√°ndo:**
- GPU NVIDIA detectada f√≠sicamente
- `torch.cuda.is_available() == True`
- `use_gpu=True` en TableProcessor

**Logs:**
```
üéÆ GPU NVIDIA detectada: Tesla T4
‚úì GPU NVIDIA/CUDA disponible, habilitando aceleraci√≥n GPU
‚úì EasyOCR inicializado en 2.5s
  üöÄ Modo: GPU NVIDIA/CUDA
  ‚ö° Aceleraci√≥n GPU activa
```

---

### Modo CPU Optimizado (Actual en AMD)
```
Hardware: AMD RX 540 / CPU Intel/AMD
Software: PyTorch CPU + quantizaci√≥n
Velocidad: ~4.67 minutos (Tabla1.pdf, 136 celdas)
Optimizaciones: Modelo quantizado, decoder greedy, canvas reducido
```

**Cu√°ndo:**
- GPU AMD/Intel/otra detectada (no CUDA)
- `torch.cuda.is_available() == False`
- Fallback autom√°tico

**Logs:**
```
‚ö†Ô∏è  GPU AMD detectada pero EasyOCR requiere NVIDIA/CUDA
   Usando CPU optimizado (quantize=True)
‚úì EasyOCR inicializado en 1.81s
  üíª Modo: CPU optimizado (quantized)
  ‚ÑπÔ∏è  Para GPU se requiere NVIDIA con CUDA
```

---

## üìä Comparativa de Rendimiento

| Hardware | Modo | Tiempo (Tabla1.pdf) | Aceleraci√≥n |
|----------|------|---------------------|-------------|
| **NVIDIA T4** (Colab) | GPU/CUDA | ~1 min | **8.5x** |
| **AMD RX 540** (Local) | CPU Optimizado | ~4.67 min | **1.82x** |
| **CPU Puro** (sin optimizar) | CPU B√°sico | ~8.5 min | 1.0x |

## üõ†Ô∏è Uso

### Inicializaci√≥n Autom√°tica
```python
from app.table_processor import TableProcessor

# Se detecta autom√°ticamente el hardware
processor = TableProcessor(
    use_gpu=True,      # Intentar√° usar GPU si es NVIDIA
    languages=['en'],
    dpi=150,
    num_cols=10
)

# Verificar qu√© modo se est√° usando
info = processor.get_info()
print(f"Modo: {info['mode']}")  
# "GPU NVIDIA/CUDA" o "CPU Optimizado"

print(f"CUDA Disponible: {info['cuda_available']}")
print(f"GPU F√≠sica: {info['gpu_type']}")
```

### Procesamiento
```python
# Mismo c√≥digo funciona en GPU NVIDIA o CPU
df = processor.process_pdf(
    pdf_path="path/to/tabla.pdf",
    pattern=['L','N','N','N','L','N','N','N','L','L']
)
```

## üîß Optimizaciones Implementadas

### Para GPU NVIDIA/CUDA:
- ‚úÖ Aceleraci√≥n GPU nativa
- ‚úÖ Batch processing en GPU
- ‚úÖ Sin cuantizaci√≥n (modelo completo)
- ‚úÖ Pin memory habilitado

### Para CPU (AMD/Otros):
- ‚úÖ Modelo quantizado (INT8)
- ‚úÖ Decoder greedy (vs beamsearch)
- ‚úÖ Canvas reducido (1280px)
- ‚úÖ Escala 2x (vs 3x original)
- ‚úÖ Interpolaci√≥n linear (vs cubic)
- ‚úÖ Thresholds optimizados

## üåê Alternativas para M√°xima Velocidad

### Google Colab (Recomendado para producci√≥n)
```python
# En Google Colab con GPU T4 gratis
!pip install easyocr pdf2image

# Mismo c√≥digo, detecta NVIDIA T4 autom√°ticamente
processor = TableProcessor(use_gpu=True)
# ‚úì GPU NVIDIA/CUDA activada ‚Üí ~1 minuto
```

### Servidor Cloud con NVIDIA
- AWS EC2 (g4dn.xlarge): NVIDIA T4
- Google Cloud (n1-standard-4 + T4)
- Azure (NC6): NVIDIA K80

## üìù Informaci√≥n de Detecci√≥n

El m√©todo `get_info()` retorna:

```python
{
    "use_gpu": False,              # GPU activada en EasyOCR
    "mode": "CPU Optimizado",      # o "GPU NVIDIA/CUDA"
    
    "gpu_type": "AMD/Other",       # Hardware f√≠sico detectado
    "backend": "OpenCL",           # API de la GPU f√≠sica
    "vram_gb": 8.0,                # VRAM de la GPU f√≠sica
    
    "cuda_available": False,       # CUDA disponible (solo NVIDIA)
    "cuda_device": "N/A",          # Nombre del dispositivo CUDA
    
    "languages": ["en"],
    "dpi": 150,
    "num_cols": 10
}
```

## ‚ö° Mejoras Futuras

- [ ] Soporte DirectML para GPU AMD en Windows
- [ ] Soporte ROCm para GPU AMD en Linux
- [ ] Apple Metal para GPU M1/M2/M3
- [ ] ONNX Runtime para inferencia multi-GPU
- [ ] PaddleOCR como alternativa m√°s r√°pida en CPU

## üÜò Troubleshooting

### "GPU AMD pero usando CPU"
**Normal**: EasyOCR no soporta AMD. El sistema autom√°ticamente usa CPU optimizado.

### "CUDA no disponible"
**Verificar**:
```python
import torch
print(torch.cuda.is_available())  # Debe ser True para NVIDIA
print(torch.cuda.get_device_name(0))  # Nombre de GPU NVIDIA
```

### "Muy lento en mi GPU NVIDIA"
**Verificar**:
1. Drivers NVIDIA actualizados
2. CUDA Toolkit instalado
3. PyTorch versi√≥n GPU: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`

## üìö Referencias

- [EasyOCR GPU Requirements](https://github.com/JaidedAI/EasyOCR#gpu-support)
- [PyTorch CUDA Setup](https://pytorch.org/get-started/locally/)
- [Google Colab Free GPU](https://colab.research.google.com/)
